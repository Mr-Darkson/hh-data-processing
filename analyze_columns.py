#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–ª–æ–Ω–æ–∫ –≤ hh.csv
"""

import pandas as pd
import sys
from pathlib import Path

def analyze_columns(filepath, max_rows=10000):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ —Ñ–∞–π–ª–∞."""
    print("üîç –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–∞...")
    print(f"–§–∞–π–ª: {filepath}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä
    size_mb = Path(filepath).stat().st_size / (1024 * 1024)
    print(f"–†–∞–∑–º–µ—Ä: {size_mb:.1f} –ú–ë")
    
    try:
        # –ß–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏
        print("\nüìã –ó–∞–≥–æ–ª–æ–≤–∫–∏ –∫–æ–ª–æ–Ω–æ–∫:")
        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
            header = f.readline().strip()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
        for sep in [',', ';', '\t', '|']:
            if sep in header:
                columns = header.split(sep)
                print(f"–†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: '{sep}'")
                print(f"–í—Å–µ–≥–æ –∫–æ–ª–æ–Ω–æ–∫: {len(columns)}")
                break
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏
        for i, col in enumerate(columns, 1):
            print(f"{i:3d}. {col}")
        
        # –ß–∏—Ç–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –æ–±—Ä–∞–∑–µ—Ü –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–∏–ø–æ–≤
        print("\nüìä –ê–Ω–∞–ª–∏–∑ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö (–ø–æ 10–∫ —Å—Ç—Ä–æ–∫):")
        df_sample = pd.read_csv(
            filepath,
            nrows=max_rows,
            sep=sep,
            low_memory=False,
            encoding='utf-8',
            on_bad_lines='skip'
        )
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º
        print("\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º:")
        for col in df_sample.columns[:15]:  # –ø–µ—Ä–≤—ã–µ 15 –∫–æ–ª–æ–Ω–æ–∫
            dtype = df_sample[col].dtype
            unique = df_sample[col].nunique()
            missing = df_sample[col].isnull().sum()
            missing_pct = (missing / len(df_sample)) * 100
            
            # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, –∫–∞–∫–∏–µ –º–æ–≥—É—Ç –±—ã—Ç—å target columns
            is_numeric = pd.api.types.is_numeric_dtype(dtype)
            is_low_cardinality = unique < 100  # –º–∞–ª–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
            
            print(f"\n{col}:")
            print(f"  –¢–∏–ø: {dtype}")
            print(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {unique}")
            print(f"  –ü—Ä–æ–ø—É—Å–∫–æ–≤: {missing} ({missing_pct:.1f}%)")
            
            # –ü–æ–¥—Å–∫–∞–∑–∫–∏ –¥–ª—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
            if is_numeric:
                print(f"  üîπ –ö–∞–Ω–¥–∏–¥–∞—Ç –≤ target (—á–∏—Å–ª–æ–≤–∞—è)")
                if unique > 10:
                    print(f"    –í–æ–∑–º–æ–∂–Ω–æ: —Ü–µ–Ω–∞, –∑–∞—Ä–ø–ª–∞—Ç–∞, —Ä–µ–π—Ç–∏–Ω–≥")
            elif is_low_cardinality:
                print(f"  üî∏ –ö–∞–Ω–¥–∏–¥–∞—Ç –≤ target (–∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–∞—è)")
                print(f"    –í–æ–∑–º–æ–∂–Ω–æ: –∫–ª–∞—Å—Å, –∫–∞—Ç–µ–≥–æ—Ä–∏—è, —Å—Ç–∞—Ç—É—Å")
            
            if unique < 10:
                print(f"  –ü—Ä–∏–º–µ—Ä—ã: {df_sample[col].unique()[:5]}")
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        print("\nüéØ –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–ï –ö–û–õ–û–ù–ö–ò –î–õ–Ø target_column:")
        candidates = []
        
        for col in df_sample.columns:
            dtype = df_sample[col].dtype
            unique = df_sample[col].nunique()
            missing = df_sample[col].isnull().sum()
            
            # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è —Ö–æ—Ä–æ—à–µ–≥–æ target
            if pd.api.types.is_numeric_dtype(dtype):
                if missing < len(df_sample) * 0.5:  # –Ω–µ –±–æ–ª–µ–µ 50% –ø—Ä–æ–ø—É—Å–∫–æ–≤
                    if 2 <= unique <= 1000:  # –Ω–µ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö
                        candidates.append((col, "numeric", unique))
            elif unique <= 10:  # –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Å –º–∞–ª—ã–º —á–∏—Å–ª–æ–º –∫–ª–∞—Å—Å–æ–≤
                if missing < len(df_sample) * 0.3:
                    candidates.append((col, "categorical", unique))
        
        if candidates:
            for col, col_type, unique in sorted(candidates, key=lambda x: x[2])[:10]:
                print(f"  - {col} ({col_type}, {unique} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö)")
        else:
            print("  –ù–µ –Ω–∞–π–¥–µ–Ω–æ –æ—á–µ–≤–∏–¥–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤. –í–æ–∑–º–æ–∂–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã:")
            for col in df_sample.columns:
                if any(keyword in col.lower() for keyword in 
                      ['salary', 'price', 'cost', 'target', 'class', 
                       'score', 'rating', 'status', 'result']):
                    print(f"  - {col}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –≤ —Ñ–∞–π–ª
        with open('columns_list.txt', 'w', encoding='utf-8') as f:
            f.write("\n".join(df_sample.columns))
        
        print(f"\nüíæ –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫–æ–ª–æ–Ω–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ 'columns_list.txt'")
        
        return df_sample.columns.tolist()
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞: {e}")
        return None

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python analyze_columns.py –ø—É—Ç—å/–∫/hh.csv")
        sys.exit(1)
    
    analyze_columns(sys.argv[1])